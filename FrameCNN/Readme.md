<h2> FRAMECNN: A WEAKLY-SUPERVISED LEARNING FRAMEWORK FOR FRAME-WISE ACOUSTIC EVENT DETECTION AND CLASSIFICATION </h2>

*- Szu-Yu Chou, Jyh-Shing Roger Jang, Yi-Hsuan Yang*

<h3> Model </h3>

<img src= "https://github.com/akshitac8/Summaries/blob/master/FrameCNN/C-ab3GBXkAAbefX.jpg" width="">
<h3> Dependenices </h3>

This implementation uses Python 2.7, Keras 2.1 and Scikit Learn. The code works on Theano backend.

```
$ pip install requirements.txt
```
<h3> Feature Extraction </h3>

- Methods Used

- Reason

<h3> Training </h3>

- Dataset
    - All files are available to download from [here](http://www.cs.tut.fi/sgn/arg/dcase2016/task-acoustic-scene-classification). Extract the contents
    
- Development Mode

- Evaluation Mode

<h3> Results </h3>

- Dev :                                                         Eva: 

<h3> References </h3>

<h3> License </h3>

MIT










