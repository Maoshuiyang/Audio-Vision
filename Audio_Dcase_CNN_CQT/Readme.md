<h3> CQT-BASED CONVOLUTIONAL NEURAL NETWORKS FOR AUDIO SCENE CLASSIFICATION AND DOMESTIC AUDIO TAGGING</h3>

*- Thomas Lidy, Alexander Schindler, Detection and Classification of Acoustic Scenes and Events, 2016*

## Model
The Model here uses parrallel CNN architecture to capture relevant feature maps for both time and frequency domain.
<img src="https://github.com/akshitac8/Summaries/blob/master/Audio_Dcase_CNN_CQT/cqt_cnn.PNG" width="738">

## Dependenices
This implementation uses Python 2.7, Keras 2.1 and Scikit Learn. The code works on Theano backend.
```
$ pip install requirements.txt
```
## Feature Extraction

- Methods Used: Normalized constant Q transform with logarithmic


## Training
- Dataset
    - All files are available to download from [here](http://www.cs.tut.fi/sgn/arg/dcase2016/task-acoustic-scene-classification). Extract the contents 
- Development Mode
- Evaluation Mode

## Results
- Dev :                                                         Eva: 

## References

## License
MIT






