<h2> SEQUENCE TO SEQUENCE AUTOENCODERS FOR UNSUPERVISED REPRESENTATION LEARNING FROM AUDIO </h2>

*- Shahin Amiriparian, Michael Freitag, Nicholas Cummins, Bjorn Schuller*

## Model

The model explained here uses recurrent autoencoder for feature extraction with MLP model for final prediction.

<img src="https://github.com/akshitac8/Summaries/blob/master/seq2seq_RNN/Presentation1.jpg" width ="850">

## Dependenices
This implementation uses Python 2.7, Keras 2.1 and Scikit Learn. The code works on Theano backend.
```
$ pip install requirements.txt
```
## Feature Extraction
- Methods Used
- Reason

## Training
- Dataset
    - All files are available to download from [here](http://www.cs.tut.fi/sgn/arg/dcase2016/task-acoustic-scene-classification). Extract the contents 
- Development Mode
- Evaluation Mode

## Results
- Dev :                                                         Eva: 

## References

## License

MIT










