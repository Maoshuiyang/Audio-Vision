{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCASE 2016 DNN Baseline\n",
    "In this notebook, we implement the **Detection and Classification of Acoustic Scenes and Events challenge** 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppress warnings**: We need to supress warnings as we are going to use some functionality of an older version of *scikit-learn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras_aud library\n",
    "Clone [keras_aud](https://github.com/channelCS/keras_aud) and place the **path** in *ka_path* variable so that we can import modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "ka_path=\"e:/akshita_workspace/cc\"\n",
    "sys.path.insert(0, ka_path)\n",
    "from keras_aud import aud_audio, aud_feature\n",
    "from keras_aud import aud_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make imports**: We now import libraries which shall be required in this task. We use\n",
    "1. `csv` for reading `.csv` files.\n",
    "2. `cPickle` for reading `.f` pickle files.\n",
    "3. `scipy` for calculating `mode`\n",
    "4. `time` for calciulating *time to load* pickle files.\n",
    "5. `KFold` for kfold cross validation.\n",
    "6. `to_categorical` for reshaping *labels* into `num_classes`.\n",
    "7. `load_model` for loading a saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define paths**: We now tell the paths for **audio**, **features** and **texts**.\n",
    "\n",
    "| Variable        | Description                     |\n",
    "| :-------------  |:-------------                   |\n",
    "| `wav_dev_fd`    | Development audio folder        |\n",
    "| `wav_eva_fd`    | Evaluation audio folder         |\n",
    "| `dev_fd`        | Development features folder     |\n",
    "| `eva_fd`        | Evaluation features folder      |\n",
    "| `label_csv`     | Development meta file           |\n",
    "| `txt_eva_path`  | Evaluation test file            |\n",
    "| `new_p`         | Evaluation evaluate file        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wav_dev_fd   = 'E:/akshita_workspace/dcase_data/audio/dev'\n",
    "wav_eva_fd   = 'E:/akshita_workspace/dcase_data/audio/eva'\n",
    "dev_fd       = 'E:/akshita_workspace/cc/features/Fe/logmel'\n",
    "eva_fd       = 'E:/akshita_workspace/cc/features/Fe_eva/logmel'\n",
    "label_csv    = 'E:/akshita_workspace/dcase_data/texts/development/meta.txt'\n",
    "txt_eva_path = 'E:/akshita_workspace/dcase_data/texts/evaluation/test.txt'\n",
    "new_p        = 'E:/akshita_workspace/dcase_data/texts/evaluation/evaluate.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Labels**: We give the names of all the labels in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [ 'bus', 'cafe/restaurant', 'car', 'city_center', 'forest_path', 'grocery_store', 'home', 'beach', \n",
    "            'library', 'metro_station', 'office', 'residential_area', 'train', 'tram', 'park' ]\n",
    "lb_to_id = { lb:id for id, lb in enumerate(labels) }\n",
    "id_to_lb = { id:lb for id, lb in enumerate(labels) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "This is where feature extraction takes place. We pass the\n",
    "1. Feature name such as mel, logmel, mfcc.\n",
    "2. Folder containing audios\n",
    "3. Folder where features will be extracted\n",
    "4. A yaml file containing parameters for features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction complete!\n",
      "Feature found\n",
      "extraction complete!\n",
      "Feature found\n"
     ]
    }
   ],
   "source": [
    "aud_audio.extract('logmel', wav_dev_fd, dev_fd,'example.yaml')\n",
    "aud_audio.extract('logmel', wav_eva_fd, eva_fd,'example.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "We define all model parameters here.\n",
    "\n",
    "| Variable           | Description              | type       | Accepted values             |\n",
    "| :-------------     | :-------------           | :--------- | :---------                  |\n",
    "| `prep`             | mode to use              | `str`      | dev, eval                   |\n",
    "| `save_model`       | Whether to save model    | `bool`     |                             |\n",
    "| `model_type`       | Type of model            | `str`      | Dynamic, Functional, Static |\n",
    "| `model`            | Name of model            | `str`      | DNN, CNN, CRNN, RNN, FCRNN  |\n",
    "| `modelx`           | Name of model for saving | `str`      | Should end with `.h5`       |\n",
    "| `feature`          | Name of feature          | `str`      | mel, logmel, cqt, mfcc, zcr |\n",
    "| **Works only for Functional** | | | |\n",
    "| `dropout1`         | 1st Dropout              | `float`    |                             |\n",
    "| `act1`             | 1st Activation           | `str`      |                             |\n",
    "| `act2`             | 2nd Activation           | `str`      |                             |\n",
    "| `act3`             | 3rd Activation           | `str`      |                             |\n",
    "| `act4`             | 4th Activation           | `str`      | Only in case of DNN         |\n",
    "| **Works for all Models** | | | |\n",
    "| `input_neurons`    | Number of Neurons        | `int`      |                             |\n",
    "| `epochs`           | Number of Epochs         | `int`      |                             |\n",
    "| `batchsize`        | Batch Size               | `int`      |                             |\n",
    "| `num_classes`      | Number of classes        | `int`      |                             |\n",
    "| `filter_length`    | Size of Filter           | `int`      |                             |\n",
    "| `nb_filter`        | Number of Filters        | `int`      |                             |\n",
    "| **Feature Parameters** | | | |\n",
    "| `agg_num`          | Number of frames         | `int`      |                             |\n",
    "| `hop`              | Hop Length               | `int`      |                             |\n",
    "| `custom_check_ftr` | check for dimensions     | `bool`     | True: know dimension        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep='eval'               # Which mode to use(String) Can be dev or eval.\n",
    "save_model=False          # True when you want to save the model with weights.\n",
    "#Parameters that are passed to the model.\n",
    "model_type='Functional'   # Type of model Can be Dynamic or Functional or Static\n",
    "model='CNN'               # Name of model(String) Can be DNN or CNN\n",
    "feature=\"logmel\"          # Name of feature(String) Can be mel logmel cqt mfcc zcr \n",
    "#Works only for Functional\n",
    "dropout1=0.1             # 1st Dropout(Float) \n",
    "act1='relu'              # 1st Activation(String) \n",
    "act2='relu'              # 2nd Activation(String) \n",
    "act3='softmax'           # 3rd Activation(String) \n",
    "#Works for all Models\n",
    "input_neurons=400      # Number of Neurons(Integer) \n",
    "epochs=100             # Number of Epochs(Integer)\n",
    "batchsize=128          # Batch Size(Integer)\n",
    "num_classes=15         # Number of classes(Integer)\n",
    "filter_length=3        # Size of Filter(Integer)\n",
    "nb_filter=100          # Number of Filters(Integer)\n",
    "#Feature Parameters: that are passed to the features.\n",
    "agg_num=10             # Agg Number(Integer) Number of frames\n",
    "hop=10                 # Hop Length(Integer)\n",
    "custom_check_ftr=False # True when you know the feature dimension else False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paul=aud_model.Feature(feature=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetAllData(fe_fd, csv_file, agg_num, hop):\n",
    "    \"\"\"\n",
    "    Input: Features folder(String), CSV file(String), agg_num(Integer), hop(Integer).\n",
    "    Output: Loaded features(Numpy Array) and labels(Numpy Array).\n",
    "    Loads all the features saved as pickle files.\n",
    "    \"\"\"\n",
    "    # read csv\n",
    "    with open( csv_file, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        lis = list(reader)\n",
    "    \n",
    "    # init list\n",
    "    X3d_all = []\n",
    "    y_all = []\n",
    "    i=0\n",
    "    for li in lis:\n",
    "        # load data\n",
    "        [na, lb] = li[0].split('\\t')\n",
    "        na = na.split('/')[1][0:-4]\n",
    "        path = fe_fd + '/' + na + '.f'\n",
    "        try:\n",
    "            X = cPickle.load( open( path, 'rb' ) )\n",
    "        except Exception as e:\n",
    "            print 'Error while parsing',path\n",
    "            continue\n",
    "        # reshape data to (n_block, n_time, n_freq)\n",
    "        i+=1\n",
    "        X3d = aud_model.mat_2d_to_3d( X, agg_num, hop )\n",
    "        X3d_all.append( X3d )\n",
    "        y_all += [ lb_to_id[lb] ] * len( X3d )\n",
    "    \n",
    "    print \"Features loaded\",i                \n",
    "    print 'All files loaded successfully'\n",
    "    # concatenate list to array\n",
    "    X3d_all = np.concatenate( X3d_all )\n",
    "    y_all = np.array( y_all )\n",
    "    \n",
    "    return X3d_all, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(md,csv_file,new_p,model):\n",
    "    # load name of wavs to be classified\n",
    "    with open( csv_file, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        lis = list(reader)\n",
    "    \n",
    "    # do classification for each file\n",
    "    names = []\n",
    "    pred_lbs = []\n",
    "    \n",
    "    for li in lis:\n",
    "        names.append( li[0] )\n",
    "        na = li[0][6:-4]\n",
    "        #audio evaluation name\n",
    "        fe_path = eva_fd + '/' + na + '.f'\n",
    "        X0 = cPickle.load( open( fe_path, 'rb' ) )\n",
    "        X0 = aud_model.mat_2d_to_3d( X0, agg_num, hop )\n",
    "        \n",
    "        X0 = aud_model.mat_3d_to_nd(model,X0)\n",
    "    \n",
    "        # predict\n",
    "        p_y_preds = md.predict(X0)        # probability, size: (n_block,label)\n",
    "        preds = np.argmax( p_y_preds, axis=-1 )     # size: (n_block)\n",
    "        b = scipy.stats.mode(preds)\n",
    "        pred = int( b[0] )\n",
    "        pred_lbs.append( id_to_lb[ pred ] )\n",
    "    \n",
    "    pred = []    \n",
    "    # write out result\n",
    "    for i1 in xrange( len( names ) ):\n",
    "        fname = names[i1] + '\\t' + pred_lbs[i1] + '\\n' \n",
    "        pred.append(fname)\n",
    "        \n",
    "    print 'write out finished!'\n",
    "    truth = open(new_p,'r').readlines()\n",
    "    pred = [i.split('\\t')[1].split('\\n')[0]for i in pred]\n",
    "    truth = [i.split('\\t')[1]for i in truth]\n",
    "    pred.sort()\n",
    "    truth.sort()\n",
    "    return truth,pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded 1170\n",
      "All files loaded successfully\n"
     ]
    }
   ],
   "source": [
    "tr_X, tr_y = GetAllData( dev_fd, label_csv, agg_num, hop )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150930L, 10L, 40L)\n",
      "(150930L,)\n"
     ]
    }
   ],
   "source": [
    "print(tr_X.shape)\n",
    "print(tr_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if custom_check_ftr:\n",
    "    reqd_dim = 40\n",
    "    paul.check_dimension(reqd_dim,tr_X.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150930L, 1L, 10L, 40L)\n"
     ]
    }
   ],
   "source": [
    "tr_X=aud_model.mat_3d_to_nd(model,tr_X)\n",
    "print(tr_X.shape)\n",
    "dimx=tr_X.shape[-2]\n",
    "dimy=tr_X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if prep=='dev':\n",
    "    cross_validation=True\n",
    "else:\n",
    "    cross_validation=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if model_type=='Static':\n",
    "    miz=aud_model.Static_Model(input_neurons=input_neurons,cross_validation=cross_validation,\n",
    "        nb_filter = nb_filter, filter_length=filter_length,\n",
    "        epochs=epochs,batchsize=batchsize,num_classes=num_classes,\n",
    "        model=model,agg_num=agg_num,hop=hop,dimx=dimx,dimy=dimy)\n",
    "\n",
    "elif model_type=='Functional':\n",
    "    miz=aud_model.Functional_Model(input_neurons=input_neurons,cross_validation=cross_validation,dropout1=dropout1,\n",
    "        act1=act1,act2=act2,act3=act3,nb_filter = nb_filter, filter_length=filter_length,\n",
    "        epochs=epochs,batchsize=batchsize,num_classes=num_classes,\n",
    "        model=model,agg_num=agg_num,hop=hop,dimx=dimx,dimy=dimy)\n",
    "\n",
    "elif model_type=='Dynamic':\n",
    "    layers=4\n",
    "    acts=['relu','relu','relu','relu','relu']\n",
    "    drops=[0.1,0.1,0.1,0.1]\n",
    "    pools=[2,2,2]\n",
    "    bn=True\n",
    "    miz=aud_model.Dynamic_Model(input_neurons=input_neurons,cross_validation=cross_validation,\n",
    "        nb_filter = nb_filter, filter_length=filter_length,\n",
    "        epochs=epochs,batchsize=batchsize,num_classes=num_classes,\n",
    "        model=model,agg_num=agg_num,hop=hop,dimx=dimx,dimy=dimy,\n",
    "        layers=layers,acts=acts,drops=drops,pools=pools,bn=bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode\n",
      "Activation 1 relu 2 relu 3 softmax\n",
      "Model CNN\n",
      "Epoch 1/100\n",
      " - 48s - loss: 1.9536 - acc: 0.3455\n",
      "Epoch 2/100\n",
      " - 48s - loss: 1.0406 - acc: 0.6401\n",
      "Epoch 3/100\n",
      " - 48s - loss: 0.7970 - acc: 0.7296\n",
      "Epoch 4/100\n",
      " - 48s - loss: 0.6670 - acc: 0.7725\n",
      "Epoch 5/100\n",
      " - 48s - loss: 0.5821 - acc: 0.8018\n",
      "Epoch 6/100\n",
      " - 48s - loss: 0.5257 - acc: 0.8200\n",
      "Epoch 7/100\n",
      " - 48s - loss: 0.4800 - acc: 0.8371\n",
      "Epoch 8/100\n",
      " - 47s - loss: 0.4450 - acc: 0.8483\n",
      "Epoch 9/100\n",
      " - 48s - loss: 0.4148 - acc: 0.8585\n",
      "Epoch 10/100\n",
      " - 47s - loss: 0.3923 - acc: 0.8661\n",
      "Epoch 11/100\n",
      " - 48s - loss: 0.3728 - acc: 0.8728\n",
      "Epoch 12/100\n",
      " - 47s - loss: 0.3539 - acc: 0.8791\n",
      "Epoch 13/100\n",
      " - 48s - loss: 0.3371 - acc: 0.8852\n",
      "Epoch 14/100\n",
      " - 48s - loss: 0.3258 - acc: 0.8883\n",
      "Epoch 15/100\n",
      " - 48s - loss: 0.3156 - acc: 0.8915\n",
      "Epoch 16/100\n",
      " - 47s - loss: 0.3041 - acc: 0.8966\n",
      "Epoch 17/100\n",
      " - 47s - loss: 0.2928 - acc: 0.8998\n",
      "Epoch 18/100\n",
      " - 48s - loss: 0.2798 - acc: 0.9036\n",
      "Epoch 19/100\n",
      " - 48s - loss: 0.2717 - acc: 0.9062\n",
      "Epoch 20/100\n",
      " - 48s - loss: 0.2651 - acc: 0.9089\n",
      "Epoch 21/100\n",
      " - 44s - loss: 0.2555 - acc: 0.9124\n",
      "Epoch 22/100\n",
      " - 29s - loss: 0.2502 - acc: 0.9133\n",
      "Epoch 23/100\n",
      " - 30s - loss: 0.2416 - acc: 0.9165\n",
      "Epoch 24/100\n",
      " - 34s - loss: 0.2345 - acc: 0.9185\n",
      "Epoch 25/100\n",
      " - 48s - loss: 0.2303 - acc: 0.9204\n",
      "Epoch 26/100\n",
      " - 47s - loss: 0.2220 - acc: 0.9235\n",
      "Epoch 27/100\n",
      " - 48s - loss: 0.2182 - acc: 0.9244\n",
      "Epoch 28/100\n",
      " - 48s - loss: 0.2144 - acc: 0.9264\n",
      "Epoch 29/100\n",
      " - 48s - loss: 0.2111 - acc: 0.9259\n",
      "Epoch 30/100\n",
      " - 48s - loss: 0.2069 - acc: 0.9286\n",
      "Epoch 31/100\n",
      " - 47s - loss: 0.2022 - acc: 0.9296\n",
      "Epoch 32/100\n",
      " - 47s - loss: 0.1965 - acc: 0.9315\n",
      "Epoch 33/100\n",
      " - 48s - loss: 0.1924 - acc: 0.9330\n",
      "Epoch 34/100\n",
      " - 48s - loss: 0.1892 - acc: 0.9337\n",
      "Epoch 35/100\n",
      " - 48s - loss: 0.1851 - acc: 0.9351\n",
      "Epoch 36/100\n",
      " - 48s - loss: 0.1844 - acc: 0.9355\n",
      "Epoch 37/100\n",
      " - 48s - loss: 0.1805 - acc: 0.9372\n",
      "Epoch 38/100\n",
      " - 47s - loss: 0.1752 - acc: 0.9386\n",
      "Epoch 39/100\n",
      " - 48s - loss: 0.1710 - acc: 0.9405\n",
      "Epoch 40/100\n",
      " - 48s - loss: 0.1683 - acc: 0.9417\n",
      "Epoch 41/100\n",
      " - 48s - loss: 0.1681 - acc: 0.9413\n",
      "Epoch 42/100\n",
      " - 47s - loss: 0.1618 - acc: 0.9434\n",
      "Epoch 43/100\n",
      " - 48s - loss: 0.1609 - acc: 0.9442\n",
      "Epoch 44/100\n",
      " - 38s - loss: 0.1575 - acc: 0.9450\n",
      "Epoch 45/100\n",
      " - 30s - loss: 0.1552 - acc: 0.9453\n",
      "Epoch 46/100\n",
      " - 30s - loss: 0.1523 - acc: 0.9472\n",
      "Epoch 47/100\n",
      " - 30s - loss: 0.1490 - acc: 0.9479\n",
      "Epoch 48/100\n",
      " - 30s - loss: 0.1467 - acc: 0.9479\n",
      "Epoch 49/100\n",
      " - 30s - loss: 0.1455 - acc: 0.9485\n",
      "Epoch 50/100\n",
      " - 30s - loss: 0.1446 - acc: 0.9492\n",
      "Epoch 51/100\n",
      " - 30s - loss: 0.1423 - acc: 0.9497\n",
      "Epoch 52/100\n",
      " - 30s - loss: 0.1373 - acc: 0.9513\n",
      "Epoch 53/100\n",
      " - 30s - loss: 0.1373 - acc: 0.9515\n",
      "Epoch 54/100\n",
      " - 30s - loss: 0.1357 - acc: 0.9522\n",
      "Epoch 55/100\n",
      " - 30s - loss: 0.1323 - acc: 0.9536\n",
      "Epoch 56/100\n",
      " - 30s - loss: 0.1301 - acc: 0.9546\n",
      "Epoch 57/100\n",
      " - 30s - loss: 0.1291 - acc: 0.9545\n",
      "Epoch 58/100\n",
      " - 30s - loss: 0.1284 - acc: 0.9547\n",
      "Epoch 59/100\n",
      " - 30s - loss: 0.1275 - acc: 0.9554\n",
      "Epoch 60/100\n",
      " - 30s - loss: 0.1235 - acc: 0.9561\n",
      "Epoch 61/100\n",
      " - 30s - loss: 0.1206 - acc: 0.9575\n",
      "Epoch 62/100\n",
      " - 30s - loss: 0.1201 - acc: 0.9574\n",
      "Epoch 63/100\n",
      " - 30s - loss: 0.1183 - acc: 0.9582\n",
      "Epoch 64/100\n",
      " - 29s - loss: 0.1172 - acc: 0.9584\n",
      "Epoch 65/100\n",
      " - 30s - loss: 0.1164 - acc: 0.9589\n",
      "Epoch 66/100\n",
      " - 29s - loss: 0.1166 - acc: 0.9588\n",
      "Epoch 67/100\n",
      " - 30s - loss: 0.1143 - acc: 0.9599\n",
      "Epoch 68/100\n",
      " - 29s - loss: 0.1124 - acc: 0.9602\n",
      "Epoch 69/100\n",
      " - 30s - loss: 0.1098 - acc: 0.9614\n",
      "Epoch 70/100\n",
      " - 30s - loss: 0.1095 - acc: 0.9617\n",
      "Epoch 71/100\n",
      " - 30s - loss: 0.1092 - acc: 0.9617\n",
      "Epoch 72/100\n",
      " - 29s - loss: 0.1059 - acc: 0.9631\n",
      "Epoch 73/100\n",
      " - 29s - loss: 0.1055 - acc: 0.9629\n",
      "Epoch 74/100\n",
      " - 30s - loss: 0.1058 - acc: 0.9628\n",
      "Epoch 75/100\n",
      " - 29s - loss: 0.1022 - acc: 0.9638\n",
      "Epoch 76/100\n",
      " - 29s - loss: 0.1014 - acc: 0.9647\n",
      "Epoch 77/100\n",
      " - 29s - loss: 0.0998 - acc: 0.9644\n",
      "Epoch 78/100\n",
      " - 29s - loss: 0.0988 - acc: 0.9649\n",
      "Epoch 79/100\n",
      " - 30s - loss: 0.0982 - acc: 0.9654\n",
      "Epoch 80/100\n",
      " - 30s - loss: 0.0967 - acc: 0.9660\n",
      "Epoch 81/100\n",
      " - 30s - loss: 0.0940 - acc: 0.9669\n",
      "Epoch 82/100\n",
      " - 29s - loss: 0.0944 - acc: 0.9666\n",
      "Epoch 83/100\n",
      " - 29s - loss: 0.0948 - acc: 0.9669\n",
      "Epoch 84/100\n",
      " - 30s - loss: 0.0933 - acc: 0.9670\n",
      "Epoch 85/100\n",
      " - 30s - loss: 0.0914 - acc: 0.9678\n",
      "Epoch 86/100\n",
      " - 29s - loss: 0.0912 - acc: 0.9673\n",
      "Epoch 87/100\n",
      " - 29s - loss: 0.0913 - acc: 0.9676\n",
      "Epoch 88/100\n",
      " - 29s - loss: 0.0868 - acc: 0.9692\n",
      "Epoch 89/100\n",
      " - 30s - loss: 0.0868 - acc: 0.9693\n",
      "Epoch 90/100\n",
      " - 29s - loss: 0.0861 - acc: 0.9697\n",
      "Epoch 91/100\n",
      " - 30s - loss: 0.0866 - acc: 0.9697\n",
      "Epoch 92/100\n",
      " - 29s - loss: 0.0855 - acc: 0.9700\n",
      "Epoch 93/100\n",
      " - 29s - loss: 0.0851 - acc: 0.9703\n",
      "Epoch 94/100\n",
      " - 30s - loss: 0.0855 - acc: 0.9699\n",
      "Epoch 95/100\n",
      " - 29s - loss: 0.0819 - acc: 0.9710\n",
      "Epoch 96/100\n",
      " - 29s - loss: 0.0832 - acc: 0.9709\n",
      "Epoch 97/100\n",
      " - 30s - loss: 0.0820 - acc: 0.9712\n",
      "Epoch 98/100\n",
      " - 29s - loss: 0.0807 - acc: 0.9719\n",
      "Epoch 99/100\n",
      " - 30s - loss: 0.0791 - acc: 0.9722\n",
      "Epoch 100/100\n",
      " - 29s - loss: 0.0808 - acc: 0.9717\n",
      "write out finished!\n",
      "Accuracy 80.51 prcnt\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1523)\n",
    "if cross_validation:\n",
    "    kf = KFold(len(tr_X),folds,shuffle=True,random_state=42)\n",
    "    results=[]    \n",
    "    for train_indices, test_indices in kf:\n",
    "        train_x = [tr_X[ii] for ii in train_indices]\n",
    "        train_y = [tr_y[ii] for ii in train_indices]\n",
    "        test_x  = [tr_X[ii] for ii in test_indices]\n",
    "        test_y  = [tr_y[ii] for ii in test_indices]\n",
    "        train_y = to_categorical(train_y,num_classes=len(labels))\n",
    "        test_y = to_categorical(test_y,num_classes=len(labels)) \n",
    "        \n",
    "        train_x=np.array(train_x)\n",
    "        train_y=np.array(train_y)\n",
    "        test_x=np.array(test_x)\n",
    "        test_y=np.array(test_y)\n",
    "        print \"Development Mode\"\n",
    "\n",
    "        #get compiled model\n",
    "        lrmodel=miz.prepare_model()\n",
    "\n",
    "        if lrmodel is None:\n",
    "            print \"If you have used Dynamic Model, make sure you pass correct parameters\"\n",
    "            raise SystemExit\n",
    "        #fit the model\n",
    "        lrmodel.fit(train_x,train_y,batch_size=miz.batchsize,epochs=miz.epochs,verbose=1)\n",
    "        \n",
    "        #make prediction\n",
    "        pred=lrmodel.predict(test_x, batch_size=32, verbose=2)\n",
    "\n",
    "        pred = [ii.argmax()for ii in pred]\n",
    "        test_y = [ii.argmax()for ii in test_y]\n",
    "\n",
    "        results.append(accuracy_score(pred,test_y))\n",
    "        print accuracy_score(pred,test_y)\n",
    "        jj=str(set(list(test_y)))\n",
    "        print \"Unique in test_y\",jj\n",
    "    print \"Results: \" + str( np.array(results).mean() )\n",
    "else:\n",
    "    train_x=np.array(tr_X)\n",
    "    train_y=np.array(tr_y)\n",
    "    print \"Evaluation mode\"\n",
    "    lrmodel=miz.prepare_model()\n",
    "    train_y = to_categorical(train_y,num_classes=len(labels))\n",
    "        \n",
    "    #fit the model\n",
    "    lrmodel.fit(train_x,train_y,batch_size=miz.batchsize,epochs=epochs,verbose=2)\n",
    "    if save_model:\n",
    "        lrmodel.save(modelx)\n",
    "        lrmodel = load_model(modelx)\n",
    "\n",
    "    truth,pred=test(lrmodel,txt_eva_path,new_p,model)\n",
    "\n",
    "    acc=aud_model.calculate_accuracy(truth,pred)\n",
    "    print \"Accuracy %.2f prcnt\"%acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
