# Framecnn: A Weakly-supervised Learning Framework For Frame-wise Acoustic Event Detection And Classification

*- Szu-Yu Chou, Jyh-Shing Roger Jang, Yi-Hsuan Yang*[[Paper](https://www.cs.tut.fi/sgn/arg/dcase2017/documents/challenge_technical_reports/DCASE2017_Chou_102.pdf)][[Dataset](http://www.cs.tut.fi/sgn/arg/dcase2016/task-audio-tagging)][[Dataset](http://www.cs.tut.fi/sgn/arg/dcase2016/task-acoustic-scene-classification)]

## Model

<img src= "./fcnn_model.jpg" width="">

### Dependenices

This implementation uses Python 2.7, Keras 2.1 and Scikit Learn. The code works on Theano backend.

```
$ pip install requirements.txt
```
## Feature Extraction

- Methods Used

- Reason

## Training

- Dataset
    - All files are available to download from [here](http://www.cs.tut.fi/sgn/arg/dcase2016/task-acoustic-scene-classification). Extract the contents
    
- Development Mode

- Evaluation Mode

### Results

- Dev :                                                         Eva: 

### References

### License

MIT
